def load_data(extracted, verified):
    """
    Load extracted and manually verified data.
    This function assumes both inputs are list of dictionaries.
    """
    return extracted, verified

def edit_distance(s1, s2):
    """
    Calculate the Levenshtein distance between two strings.
    """
    if len(s1) > len(s2):
        s1, s2 = s2, s1

    distances = range(len(s1) + 1)
    for index2, char2 in enumerate(s2):
        new_distances = [index2 + 1]
        for index1, char1 in enumerate(s1):
            if char1 == char2:
                new_distances.append(distances[index1])
            else:
                new_distances.append(1 + min((distances[index1], distances[index1 + 1], new_distances[-1])))
        distances = new_distances
    return distances[-1]

def dynamic_edit_distance_tolerance(length):
    """
    Define the tolerance level for edit distance based on the length of the string.
    """
    if length < 5:
        return 1
    elif length <= 10:
        return 2
    else:
        return 3

def clean_data_with_custom_edit_distance(extracted, verified_keys):
    """
    Clean the extracted data by matching keys using custom edit distance within a tolerance determined by string length.
    """
    cleaned_data = []
    for item in extracted:
        key, value = list(item.items())[0]
        key_clean = key.strip().lower()
        
        # Find the best match based on edit distance within the defined tolerance
        best_match = None
        min_distance = float('inf')
        for verified_key in verified_keys:
            verified_key_clean = verified_key.strip().lower()
            distance = edit_distance(key_clean, verified_key_clean)
            tolerance = dynamic_edit_distance_tolerance(len(verified_key_clean))
            if distance <= tolerance and distance < min_distance:
                min_distance = distance
                best_match = verified_key
        
        # Use the best match if found, otherwise use the original key
        corrected_key = best_match if best_match else key
        cleaned_data.append({corrected_key: value})
    
    return cleaned_data

def calculate_metrics(extracted, verified):
    """
    Calculate precision, recall, and F1-score.
    Args:
        extracted (list): List of dictionaries containing the extracted results.
        verified (list): List of dictionaries containing the manually verified correct results.
    Returns:
        tuple: Returns precision, recall, and F1 score.
    """
    # Flatten the list of dictionaries to a single dictionary for easier comparison
    extracted_flat = {list(item.keys())[0]: list(item.values())[0] for item in extracted}
    verified_flat = {list(item.keys())[0]: list(item.values())[0] for item in verified}

    true_positives = sum(1 for key in extracted_flat if key in verified_flat and extracted_flat[key] == verified_flat[key])
    false_positives = sum(1 for key in extracted_flat if key not in verified_flat or extracted_flat[key] != verified_flat[key])
    false_negatives = sum(1 for key in verified_flat if key not in extracted_flat or extracted_flat[key] != verified_flat[key])

    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    return precision, recall, f1_score

# Example function calls (commented out):
# extracted_cleaned = clean_data_with_custom_edit_distance(extracted_results, verified_keys)
# precision, recall, f1_score = calculate_metrics(extracted_cleaned, verified_results)
# print(f"Precision: {precision}, Recall: {recall}, F1 Score: {f1_score}")
